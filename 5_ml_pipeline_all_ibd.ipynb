{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciKit-Learn Pipeline (All IBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chershiongchuah/Developer/machine_learning_for_ibd_fatigue/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    recall_score,\n",
    "    auc,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    ")\n",
    "import shap\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    "    GroupKFold,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from src.data.preprocessing import load_and_preprocess_data\n",
    "from src.config.constants import NUMERICAL_FEATURES, RANDOM_SEED\n",
    "from src.config.sklearn_models import models_and_params\n",
    "from src.data.splitting import split_data_for_sklearn\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biochemical_remission = False\n",
    "random_seed = RANDOM_SEED\n",
    "\n",
    "if biochemical_remission:\n",
    "    output_path = \"output/biochem_remission/\"\n",
    "    cmap = \"berlin\"\n",
    "    file_prefix = \"biochem_remission\"\n",
    "    df = load_and_preprocess_data(biochemical_remission=True)\n",
    "else:\n",
    "    df = load_and_preprocess_data(biochemical_remission=False)\n",
    "    output_path = \"output/all_ibd/\"\n",
    "    cmap = \"seismic\"\n",
    "    file_prefix = \"all_ibd\"\n",
    "\n",
    "plt.rcParams[\"font.family\"] = [\"Roboto\", \"Arial\", \"sans-serif\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = NUMERICAL_FEATURES\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[numerical_features])\n",
    "df[numerical_features] = scaler.transform(df[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Find the best hyperparameters for each of the six models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearch for Random Forest...\n",
      "Running GridSearch for Logistic Regression...\n",
      "Running GridSearch for AdaBoost...\n",
      "Running GridSearch for XGBoost...\n",
      "Running GridSearch for SVC...\n",
      "Running GridSearch for MLPClassifier...\n",
      "                                                           best_params  \\\n",
      "Random Forest        {'max_depth': 5, 'min_samples_split': 2, 'n_es...   \n",
      "Logistic Regression     {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}   \n",
      "AdaBoost                   {'learning_rate': 0.1, 'n_estimators': 100}   \n",
      "XGBoost              {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
      "SVC                                          {'C': 10, 'gamma': 0.001}   \n",
      "MLPClassifier        {'activation': 'tanh', 'hidden_layer_sizes': (...   \n",
      "\n",
      "                    mean_score std_score  \\\n",
      "Random Forest         0.767779  0.017777   \n",
      "Logistic Regression   0.761771  0.021266   \n",
      "AdaBoost              0.764821  0.009992   \n",
      "XGBoost               0.762286  0.010251   \n",
      "SVC                   0.767342  0.020329   \n",
      "MLPClassifier         0.764546  0.018067   \n",
      "\n",
      "                                                                  grid  \n",
      "Random Forest        GridSearchCV(cv=GroupKFold(n_splits=5),\\n     ...  \n",
      "Logistic Regression  GridSearchCV(cv=GroupKFold(n_splits=5),\\n     ...  \n",
      "AdaBoost             GridSearchCV(cv=GroupKFold(n_splits=5),\\n     ...  \n",
      "XGBoost              GridSearchCV(cv=GroupKFold(n_splits=5),\\n     ...  \n",
      "SVC                  GridSearchCV(cv=GroupKFold(n_splits=5),\\n     ...  \n",
      "MLPClassifier        GridSearchCV(cv=GroupKFold(n_splits=5),\\n     ...  \n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, groups = split_data_for_sklearn(df)\n",
    "\n",
    "# Models and parameter grids\n",
    "models_and_params = models_and_params\n",
    "\n",
    "# GroupKFold cross-validation method with 5 splits\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "# Results storage\n",
    "results = {}\n",
    "\n",
    "for model_name, (model, param_grid) in models_and_params.items():\n",
    "    print(f\"Running GridSearch for {model_name}...\")\n",
    "    grid = GridSearchCV(\n",
    "        estimator=model, param_grid=param_grid, cv=cv, n_jobs=-1, scoring=\"roc_auc\"\n",
    "    )\n",
    "    grid.fit(\n",
    "        X_train, y_train, groups=groups\n",
    "    )  # Pass groups to ensure grouping of study_id into either train or validate sets\n",
    "\n",
    "    # Extract best parameters, mean, and standard deviation of test scores\n",
    "    results[model_name] = {\n",
    "        \"best_params\": grid.best_params_,\n",
    "        \"mean_score\": grid.cv_results_[\"mean_test_score\"][grid.best_index_],\n",
    "        \"std_score\": grid.cv_results_[\"std_test_score\"][grid.best_index_],\n",
    "        \"grid\": grid,  # Save the grid object for future use\n",
    "    }\n",
    "\n",
    "# Display Results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store fitted models and their AUC scores, including mean and SD\n",
    "fitted_models = {}\n",
    "roc_results = {}\n",
    "\n",
    "# Loop through the models and evaluate mean and SD of AUC\n",
    "for model_name, (model, _) in models_and_params.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "\n",
    "    # Get best parameters from grid search\n",
    "    best_params = results[model_name][\"best_params\"]\n",
    "\n",
    "    # Initialize the model with best parameters\n",
    "    best_model = model.set_params(**best_params)\n",
    "\n",
    "    # Perform cross-validation with GroupKFold\n",
    "    cv_auc_scores = cross_val_score(\n",
    "        best_model, X_train, y_train, cv=cv, groups=groups, scoring=\"roc_auc\", n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Compute mean and SD of AUC\n",
    "    mean_auc = np.mean(cv_auc_scores)\n",
    "    std_auc = np.std(cv_auc_scores)\n",
    "\n",
    "    # Fit the model to the entire training set\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Store the fitted model\n",
    "    fitted_models[model_name] = best_model\n",
    "\n",
    "    # Predict probabilities for the test set\n",
    "    y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Compute ROC curve and AUC on the test set\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_test_proba)\n",
    "    test_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Store the results for plotting\n",
    "    roc_results[model_name] = {\n",
    "        \"fpr\": fpr,\n",
    "        \"tpr\": tpr,\n",
    "        \"test_auc\": test_auc,\n",
    "        \"mean_auc\": mean_auc,\n",
    "        \"std_auc\": std_auc,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for all models with mean and SD of AUC\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.rcParams[\"font.family\"] = \"Roboto\"\n",
    "for model_name, roc_data in roc_results.items():\n",
    "    mean_auc = roc_data[\"mean_auc\"]\n",
    "    std_auc = roc_data[\"std_auc\"]\n",
    "    test_auc = roc_data[\"test_auc\"]\n",
    "    plt.plot(\n",
    "        roc_data[\"fpr\"],\n",
    "        roc_data[\"tpr\"],\n",
    "        label=f\"{model_name} (Test AUC = {test_auc:.2f})\",\n",
    "    )\n",
    "\n",
    "# Add in Keras DNN Model\n",
    "\n",
    "# Load the model\n",
    "if biochemical_remission:\n",
    "    read_dir = \"output/dnn_biochem_remission/\"\n",
    "else:\n",
    "    read_dir = \"output/dnn/\"\n",
    "\n",
    "dnn_fpr = np.loadtxt(f\"{read_dir}dnn_fpr.txt\")\n",
    "dnn_tpr = np.loadtxt(f\"{read_dir}/dnn_tpr.txt\")\n",
    "\n",
    "with open(f\"{read_dir}dnn_metrics.json\", \"r\") as f:\n",
    "    dnn_metrics = json.load(f)\n",
    "\n",
    "dnn_auc = dnn_metrics[\"auc\"]\n",
    "        \n",
    "plt.plot(dnn_fpr, dnn_tpr, label=f\"Deep Neural Network (Test AUC = {dnn_auc:.2f})\", linewidth=4)\n",
    "\n",
    "# Add baseline and plot details\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Chance (AUC = 0.50)\")\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=20, fontweight=\"bold\")\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=20, fontweight=\"bold\")\n",
    "\n",
    "if biochemical_remission:\n",
    "    plt.title(\"DNN outperforms other ML algorithms (Biochemical Remission)\", fontsize=24, fontweight=\"bold\", pad=40)\n",
    "else:\n",
    "    plt.title(\"DNN outperforms other ML algorithms (All IBD)\", fontsize=24, fontweight=\"bold\", pad=40)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "\n",
    "\n",
    "# Remove the top and right spines\n",
    "ax = plt.gca()\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "ax.xaxis.label.set_fontweight(\"bold\")\n",
    "ax.yaxis.label.set_fontweight(\"bold\")\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=16, width=2)\n",
    "\n",
    "\n",
    "# Define the absolute path\n",
    "save_path = f\"{output_path}{file_prefix}_roc_curves.png\"\n",
    "\n",
    "# Save the plot to the specified path\n",
    "plt.savefig(save_path, dpi=600, bbox_inches=\"tight\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Metrics Stored in CSV Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store metrics for each model\n",
    "metrics_results = []\n",
    "\n",
    "for model_name, best_model in fitted_models.items():\n",
    "    print(f\"Evaluating metrics for {model_name}...\")\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    y_test_proba = best_model.predict_proba(X_test)[:, 1]  # Probabilities for AUC\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    sensitivity = recall_score(y_test, y_test_pred)  # TPR\n",
    "    specificity = tn / (tn + fp)  # TNR\n",
    "    auc_score = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "    # Store results\n",
    "    metrics_results.append(\n",
    "        {\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Sensitivity (Recall)\": sensitivity,\n",
    "            \"Specificity\": specificity,\n",
    "            \"AUC\": auc_score,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Add in DNN Metrics Here\n",
    "metrics_results.append(\n",
    "    {\n",
    "        \"Model\": \"Deep Neural Network\",\n",
    "        \"Accuracy\": dnn_metrics[\"accuracy\"],\n",
    "        \"Sensitivity (Recall)\": dnn_metrics[\"sensitivity\"],\n",
    "        \"Specificity\": dnn_metrics[\"specificity\"],\n",
    "        \"AUC\": dnn_metrics[\"auc\"],\n",
    "    }\n",
    ")\n",
    "# Convert to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_results).sort_values(\"AUC\", ascending=False)\n",
    "\n",
    "metrics_df = metrics_df.round(3)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = f\"{output_path}{file_prefix}_model_metrics.csv\"\n",
    "metrics_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Metrics saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Plots for Each Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the GridSearchCV object for Random Forest\n",
    "rf_grid = results[\"Random Forest\"][\"grid\"]\n",
    "\n",
    "# Retrieve the best Random Forest model\n",
    "rf_best_model = rf_grid.best_estimator_\n",
    "\n",
    "# SHAP Analysis\n",
    "explainer = shap.TreeExplainer(rf_best_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Extract SHAP values\n",
    "shap_values_class_1 = shap_values[:, :, 1]\n",
    "\n",
    "# Correct feature names as a list\n",
    "feature_names = X_test.columns.tolist()\n",
    "\n",
    "# Plot SHAP summary plot with correct feature names\n",
    "shap.summary_plot(\n",
    "    shap_values_class_1, X_test, feature_names=feature_names, show=False, cmap=cmap\n",
    ")\n",
    "\n",
    "plt.title(\"Random Forest\", fontsize=20, pad=20, loc=\"left\")\n",
    "\n",
    "save_path = f\"{output_path}shap_random_forest.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the GridSearchCV object for Logistic Regression\n",
    "logreg_grid = results[\"Logistic Regression\"][\"grid\"]\n",
    "\n",
    "# Retrieve the best Logistic Regression model\n",
    "logreg_best_model = logreg_grid.best_estimator_\n",
    "\n",
    "# SHAP plot for logistic regression on test set\n",
    "masker = shap.maskers.Independent(data=X_test)\n",
    "explainer = shap.LinearExplainer(logreg_best_model, masker=masker)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(\n",
    "    shap_values, X_test, feature_names=X_test.columns, show=False, cmap=cmap\n",
    ")\n",
    "\n",
    "plt.title(\"Logistic Regression\", fontsize=20, pad=20, loc=\"left\")\n",
    "plt.xlim(-1, 1)\n",
    "\n",
    "save_path = f\"{output_path}shap_logistic_regression.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the GridSearchCV object for AdaBoost\n",
    "adaboost_grid = results[\"AdaBoost\"][\"grid\"]\n",
    "\n",
    "# Retrieve the best Logistic Regression model\n",
    "adaboost_best_model = adaboost_grid.best_estimator_\n",
    "\n",
    "X_test_sample = shap.sample(X_test, 50)\n",
    "explainer = shap.KernelExplainer(adaboost_best_model.predict_proba, X_test_sample)\n",
    "shap_values = explainer.shap_values(X_test_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_class_1 = shap_values[:, :, 1]\n",
    "shap.summary_plot(\n",
    "    shap_values_class_1,\n",
    "    X_test_sample,\n",
    "    feature_names=X_test_sample.columns,\n",
    "    show=False,\n",
    "    cmap=cmap,\n",
    ")\n",
    "\n",
    "plt.title(\"AdaBoost\", fontsize=20, pad=20, loc=\"left\")\n",
    "\n",
    "save_path = f\"{output_path}shap_adaboost.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the GridSearchCV object for AdaBoost\n",
    "xgboost_grid = results[\"XGBoost\"][\"grid\"]\n",
    "\n",
    "# Retrieve the best Logistic Regression model\n",
    "xgboost_best_model = xgboost_grid.best_estimator_\n",
    "\n",
    "explainer = shap.Explainer(xgboost_best_model, X_test)\n",
    "shap_values = explainer(X_test)\n",
    "shap.plots.beeswarm(shap_values, max_display=20, show=False, color=plt.get_cmap(cmap))\n",
    "plt.title(\"XGBoost\", fontsize=20, pad=20, loc=\"left\")\n",
    "\n",
    "save_path = f\"{output_path}shap_xgboost.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the GridSearchCV object for MLPClassifier\n",
    "mlp_grid = results[\"MLPClassifier\"][\"grid\"]\n",
    "\n",
    "mlp_best_model = mlp_grid.best_estimator_\n",
    "\n",
    "X_test_sample = shap.sample(X_test, 50)\n",
    "explainer = shap.KernelExplainer(mlp_best_model.predict_proba, X_test_sample)\n",
    "shap_values = explainer.shap_values(X_test_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_class_1 = shap_values[:, :, 1]\n",
    "shap.summary_plot(\n",
    "    shap_values_class_1,\n",
    "    X_test_sample,\n",
    "    feature_names=X_test_sample.columns,\n",
    "    show=False,\n",
    "    cmap=cmap,\n",
    ")\n",
    "\n",
    "plt.title(\"MLP Classifier\", fontsize=20, pad=20, loc=\"left\")\n",
    "\n",
    "save_path = f\"{output_path}shap_mlp.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the GridSearchCV object for MLPClassifier\n",
    "svc_grid = results[\"SVC\"][\"grid\"]\n",
    "\n",
    "svc_best_model = svc_grid.best_estimator_\n",
    "\n",
    "X_test_sample = shap.sample(X_test, 40)\n",
    "explainer = shap.KernelExplainer(svc_best_model.predict_proba, X_test_sample)\n",
    "shap_values = explainer.shap_values(X_test_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_class_1 = shap_values[:, :, 1]\n",
    "shap.summary_plot(\n",
    "    shap_values_class_1,\n",
    "    X_test_sample,\n",
    "    feature_names=X_test_sample.columns,\n",
    "    show=False,\n",
    "    max_display=20,\n",
    "    cmap=cmap,\n",
    ")\n",
    "\n",
    "plt.title(\"Support Vector Classifier\", fontsize=20, pad=20, loc=\"left\")\n",
    "\n",
    "save_path = f\"{output_path}shap_svc.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
