{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Production Optimisation\n",
    "\n",
    "Removal of low value features to simplify model for production deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    recall_score,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    ")\n",
    "import shap\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    GroupShuffleSplit,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import AUC\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1337  # Random seed to ensure reproducibility\n",
    "output_path = \"output/tensorflow_optimisation/\"\n",
    "cmap = \"seismic\"  # Colormap for SHAP plots use \"seismic\" for full cohort and \"berlin\" for biochem remission cohort\n",
    "file_prefix = \"tensorflow_optimisation\"\n",
    "# file_prefix = \"biochem_remission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"working_data/all_ibd_ml_input.csv\")\n",
    "# df = df[df[\"aggregate_disease_activity_Biochemical remission\"] == 1] # Uncomment to run biochem remission pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical columns to numerical\n",
    "df[\"sex\"] = df[\"sex\"].map({\"Male\": 1, \"Female\": 0})\n",
    "df[\"fatigue_outcome\"] = df[\"fatigue_outcome\"].map({\"fatigue\": 1, \"no_fatigue\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These columns are not features we want to use in the model\n",
    "# Aggregate disease activity in some ways is a reflection of the other raw variables\n",
    "columns_to_drop = [\n",
    "    \"aggregate_disease_activity_Active\",\n",
    "    \"aggregate_disease_activity_Biochemical remission\",\n",
    "    \"aggregate_disease_activity_Remission\",\n",
    "    \"season_no_data\",\n",
    "    \"study\",\n",
    "    \"redcap_event_name_timepoint_1\",\n",
    "    \"redcap_event_name_timepoint_2\",\n",
    "    \"redcap_event_name_timepoint_3\",\n",
    "    \"redcap_event_name_timepoint_4\",\n",
    "    \"redcap_event_name_timepoint_5\",\n",
    "]\n",
    "\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This column is dropped as all the values are 0.\n",
    "columns_to_drop = [\n",
    "    \"baseline_eims_pyoderma_gangrenosum\",\n",
    "]\n",
    "\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed to simplify deployment\n",
    "columns_to_drop = [\n",
    "    \"has_active_symptoms\",\n",
    "]\n",
    "\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will drop features that are not highly weighted to simplify the input model\n",
    "\n",
    "columns_to_drop = [\n",
    "    \"baseline_eims_arthralgia_arthritis\",\n",
    "    \"baseline_eims_ankylosing_spondylitis\",\n",
    "    \"baseline_eims_erythema_nodosum\",\n",
    "    \"baseline_eims_uveitis\",\n",
    "    \"baseline_eims_scleritis_episclerities\",\n",
    "    \"is_smoker_smokeryn1\",\n",
    "    \"study_group_name_Await Dx\",\n",
    "    \"ifx_drug_level\",\n",
    "    \"ada_drug_level\",\n",
    "    \"ifx_drug_level_present\",\n",
    "    \"ada_drug_level_present\",\n",
    "    \"ifx_antibody_present\",\n",
    "    \"ada_antibody_present\",\n",
    "    \"haematocrit\",\n",
    "]\n",
    "\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Datasets\n",
    "\n",
    "GroupShuffleSplit used to ensure same participant only appears in either train or test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train Validate and Test Datasets\n",
    "\n",
    "# First split into train and temp 70% train, 30% temp which will be split 50:50 into 15% val and 15% test\n",
    "\n",
    "# GroupShuffleSplit\n",
    "splitter = GroupShuffleSplit(test_size=0.36, n_splits=1, random_state=random_seed)\n",
    "\n",
    "# Perform the split\n",
    "for train_idx, test_idx in splitter.split(df, groups=df[\"study_id\"]):\n",
    "    train_data = df.iloc[train_idx]\n",
    "    temp_data = df.iloc[test_idx]\n",
    "\n",
    "# Drop 'study_id' from X_train and X_test as it's not a feature\n",
    "X_train = train_data.drop(columns=[\"fatigue_outcome\", \"study_id\"])\n",
    "y_train = train_data[\"fatigue_outcome\"]\n",
    "\n",
    "groups = train_data[\"study_id\"]  # Group variable for GroupKFold cross-validation\n",
    "\n",
    "temp_data_splitter = GroupShuffleSplit(\n",
    "    test_size=0.56, n_splits=1, random_state=random_seed\n",
    ")\n",
    "\n",
    "# Perform the split\n",
    "for val_idx, test_idx in temp_data_splitter.split(\n",
    "    temp_data, groups=temp_data[\"study_id\"]\n",
    "):\n",
    "    val_data = df.iloc[val_idx]\n",
    "    test_data = df.iloc[test_idx]\n",
    "\n",
    "X_val = val_data.drop(columns=[\"fatigue_outcome\", \"study_id\"])\n",
    "y_val = val_data[\"fatigue_outcome\"]\n",
    "\n",
    "X_test = test_data.drop(columns=[\"fatigue_outcome\", \"study_id\"])\n",
    "y_test = test_data[\"fatigue_outcome\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Val shape:\", X_val.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    \"age\",\n",
    "    \"height\",\n",
    "    \"weight\",\n",
    "    \"bmi\",\n",
    "    \"age_at_diagnosis\",\n",
    "    \"albumin\",\n",
    "    \"crp\",\n",
    "    \"haemoglobin\",\n",
    "    \"red_cell_count\",\n",
    "    # \"haematocrit\",\n",
    "    \"white_cell_count\",\n",
    "    \"neutrophils\",\n",
    "    \"lymphocytes\",\n",
    "    \"monocytes\",\n",
    "    \"eosinophils\",\n",
    "    \"basophils\",\n",
    "    \"platelets\",\n",
    "    \"urea\",\n",
    "    \"creatinine\",\n",
    "    \"sodium\",\n",
    "    \"potassium\",\n",
    "    \"calprotectin\",\n",
    "    # \"ada_drug_level\",\n",
    "    # \"ifx_drug_level\",\n",
    "    \"diagnosis_year\",\n",
    "    \"disease_duration_weeks\",\n",
    "]\n",
    "\n",
    "X_unified = pd.concat([X_train, X_val, X_test])\n",
    "unified_scaler = StandardScaler()\n",
    "unified_scaler.fit(X_unified[numerical_features])\n",
    "\n",
    "X_train[numerical_features] = unified_scaler.transform(X_train[numerical_features])\n",
    "\n",
    "X_test[numerical_features] = unified_scaler.transform(X_test[numerical_features])\n",
    "\n",
    "X_val[numerical_features] = unified_scaler.transform(X_val[numerical_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(unified_scaler, output_path + \"export/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(output_path + \"export/X_train.csv\", index=False)\n",
    "X_test.to_csv(output_path + \"export/X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with TensorFlow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(384, activation=\"relu\"),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(352, activation=\"relu\"),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"auc\", patience=10, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{output_path}export/fatigue_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_values = history_dict[\"auc\"]\n",
    "val_auc_values = history_dict[\"val_auc\"]\n",
    "epochs = range(1, len(auc_values) + 1)\n",
    "plt.plot(epochs, auc_values, \"bo\", label=\"Training AUC\")\n",
    "plt.plot(epochs, val_auc_values, \"b\", label=\"Validation AUC\")\n",
    "plt.title(\"Training and validation AUC\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.legend()\n",
    "\n",
    "save_path = output_path + file_prefix + \"_training_vs_validation_loss.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "save_path = output_path + file_prefix + \"_training_vs_validation_loss.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc = history_dict[\"auc\"]\n",
    "val_acc = history_dict[\"val_auc\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
    "plt.title(\"Training and validation AUC\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.legend()\n",
    "save_path = output_path + file_prefix + \"_training_vs_validation_auc.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "test_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "y_classes = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_classes).ravel()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_classes)\n",
    "sensitivity = recall_score(y_test, y_classes)  # TPR\n",
    "specificity = tn / (tn + fp)  # TN\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"AUC:\", test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(output_path + \"dnn_fpr.txt\", fpr)\n",
    "np.savetxt(output_path + \"dnn_tpr.txt\", tpr)\n",
    "\n",
    "with open(output_path + \"dnn_auc.txt\", \"w\") as f:\n",
    "    f.write(str(test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    label=f\"AUC = {test_auc:.4f}\",\n",
    ")\n",
    "\n",
    "# Add baseline and plot details\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Chance (AUC = 0.50)\")\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=14)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=14)\n",
    "plt.title(\"Performance of Keras DNN on Test Set\", fontsize=16, fontweight=\"bold\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Remove the top and right spines\n",
    "ax = plt.gca()\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Define the absolute path\n",
    "save_path = f\"{output_path}{file_prefix}_roc_curves.png\"\n",
    "\n",
    "# Save the plot to the specified path\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Tensorboard Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To launch tensorboard run the following in terminal:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir logs/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Analysis on Keras DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(model, X_train[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(\n",
    "    explainer.expected_value[0],\n",
    "    shap_values[:1, :, 0],\n",
    "    X_test[:1],\n",
    "    matplotlib=True,\n",
    "    contribution_threshold=0.05,\n",
    "    text_rotation=30,\n",
    "    show=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path + \"export/shap_explainer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(explainer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_path}export/shap_explainer.pkl\", \"rb\") as f:\n",
    "    new_explainer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_test = new_explainer.shap_values(X_test.iloc[1])\n",
    "\n",
    "print(shap_values_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(\n",
    "    explainer.expected_value[0],\n",
    "    shap_values_test[:, 0],\n",
    "    X_test.iloc[1],\n",
    "    matplotlib=True,\n",
    "    contribution_threshold=0.05,\n",
    "    text_rotation=30,\n",
    "    show=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_class_1 = shap_values[:, :, 0]\n",
    "shap.summary_plot(\n",
    "    shap_values_class_1,\n",
    "    X_test,\n",
    "    feature_names=X_test.columns,\n",
    "    show=False,\n",
    "    cmap=cmap,\n",
    ")\n",
    "\n",
    "# plt.title(\"Keras DNN Classifier\", fontsize=20, pad=20, loc=\"left\")\n",
    "\n",
    "save_path = f\"{output_path}shap_keras_dnn.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values_class_1,\n",
    "    X_test,\n",
    "    feature_names=X_test.columns,\n",
    "    show=False,\n",
    "    cmap=cmap,\n",
    "    plot_type=\"bar\",\n",
    "    max_display=85,\n",
    ")\n",
    "\n",
    "\n",
    "plt.title(\"Keras DNN Classifier - Top 10 Features\", fontsize=20, pad=20, loc=\"left\")\n",
    "\n",
    "save_path = f\"{output_path}shap_keras_dnn_barplot.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reverted = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reverted[numerical_features] = unified_scaler.inverse_transform(\n",
    "    X_test[numerical_features]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reverted[numerical_features] = X_test_reverted[numerical_features].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    shap.force_plot(\n",
    "        explainer.expected_value[0],\n",
    "        shap_values_class_1[i],\n",
    "        X_test_reverted.iloc[i],\n",
    "        matplotlib=True,\n",
    "        contribution_threshold=0.05,\n",
    "        text_rotation=30,\n",
    "        show=False,\n",
    "    )\n",
    "\n",
    "    save_path = f\"{output_path}forceplots/keras_dnn_forceplot_{i}.png\"\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
